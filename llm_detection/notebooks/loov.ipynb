{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6856a260-266f-4294-97ec-2822e65a7e0e",
   "metadata": {},
   "source": [
    "# Leave-One-Out Validation for Generated Essays\n",
    "\n",
    "This is an auxiliary notebook which complements the [main notebook](llm_detection.ipynb). \n",
    "\n",
    "We run a script which calculates the prediction probability of each individual generated text. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b245bdf5-eb1e-4933-a507-45b955d1db7b",
   "metadata": {},
   "source": [
    "## Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26584ef6-7959-477a-aa3f-6c1e3d83f054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3923992c5c614eabb4c185bfdf0555ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm_notebook\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import notebook_config\n",
    "\n",
    "\n",
    "# enable progress bar functionality\n",
    "tqdm_notebook().pandas()\n",
    "\n",
    "\n",
    "INTERMEDIATE_DIR = os.path.join(\"..\", notebook_config.INTERMEDIATE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8424b185-e105-41d1-9cdf-4e1461573045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>generated</th>\n",
       "      <th>llm</th>\n",
       "      <th>source</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-520228841973214070</td>\n",
       "      <td>cars have been a major part of our lives for a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PaLM</td>\n",
       "      <td>Konstantina Liagkou</td>\n",
       "      <td>[ 8.0638006e-02  1.6982207e+00 -2.5302460e+00 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6608331338134701053</td>\n",
       "      <td>limiting car usage has many advantages, such a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PaLM</td>\n",
       "      <td>Konstantina Liagkou</td>\n",
       "      <td>[-0.8870298  -0.45862535 -3.3064713  -0.091987...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7138188490374180722</td>\n",
       "      <td>\"america's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PaLM</td>\n",
       "      <td>Konstantina Liagkou</td>\n",
       "      <td>[ 9.11974728e-01  1.03492856e+00 -1.52655876e+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3084568973721699379</td>\n",
       "      <td>cars are convenient, but they can be harmful t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PaLM</td>\n",
       "      <td>Konstantina Liagkou</td>\n",
       "      <td>[-0.90010715 -0.37471777 -3.003909   -0.017782...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4989392494283758830</td>\n",
       "      <td>cars are a convenient way to get around, but t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PaLM</td>\n",
       "      <td>Konstantina Liagkou</td>\n",
       "      <td>[-8.3860934e-02 -2.7152100e-01 -3.4049506e+00 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5248</th>\n",
       "      <td>fe6ff9a5</td>\n",
       "      <td>there has been a fuss about the elector colleg...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Human</td>\n",
       "      <td>Competition</td>\n",
       "      <td>[-1.4767352   0.04409365 -2.265938    0.227724...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5249</th>\n",
       "      <td>ff669174</td>\n",
       "      <td>limiting car usage has many advantages. such a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Human</td>\n",
       "      <td>Competition</td>\n",
       "      <td>[-2.03082055e-01  8.64372015e-01 -3.53538036e+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5250</th>\n",
       "      <td>ffa247e0</td>\n",
       "      <td>there's a new trend that has been developing f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Human</td>\n",
       "      <td>Competition</td>\n",
       "      <td>[-8.06897342e-01  1.52280945e-02 -2.08817863e+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5251</th>\n",
       "      <td>ffc237e9</td>\n",
       "      <td>as we all know cars are a big part of our soci...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Human</td>\n",
       "      <td>Competition</td>\n",
       "      <td>[-6.59209251e-01  1.89325139e-01 -2.40648055e+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5252</th>\n",
       "      <td>ffe1ca0d</td>\n",
       "      <td>cars have been around since the 1800's and hav...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Human</td>\n",
       "      <td>Competition</td>\n",
       "      <td>[-0.37164244  0.2070003  -2.5946207  -0.715533...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5253 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                               text  \\\n",
       "0      -520228841973214070  cars have been a major part of our lives for a...   \n",
       "1      6608331338134701053  limiting car usage has many advantages, such a...   \n",
       "2      7138188490374180722  \"america's love affair with it's vehicles seem...   \n",
       "3      3084568973721699379  cars are convenient, but they can be harmful t...   \n",
       "4     -4989392494283758830  cars are a convenient way to get around, but t...   \n",
       "...                    ...                                                ...   \n",
       "5248              fe6ff9a5  there has been a fuss about the elector colleg...   \n",
       "5249              ff669174  limiting car usage has many advantages. such a...   \n",
       "5250              ffa247e0  there's a new trend that has been developing f...   \n",
       "5251              ffc237e9  as we all know cars are a big part of our soci...   \n",
       "5252              ffe1ca0d  cars have been around since the 1800's and hav...   \n",
       "\n",
       "      prompt_id  generated    llm               source  \\\n",
       "0             0          1   PaLM  Konstantina Liagkou   \n",
       "1             0          1   PaLM  Konstantina Liagkou   \n",
       "2             0          1   PaLM  Konstantina Liagkou   \n",
       "3             0          1   PaLM  Konstantina Liagkou   \n",
       "4             0          1   PaLM  Konstantina Liagkou   \n",
       "...         ...        ...    ...                  ...   \n",
       "5248          1          0  Human          Competition   \n",
       "5249          0          0  Human          Competition   \n",
       "5250          0          0  Human          Competition   \n",
       "5251          0          0  Human          Competition   \n",
       "5252          0          0  Human          Competition   \n",
       "\n",
       "                                              embedding  \n",
       "0     [ 8.0638006e-02  1.6982207e+00 -2.5302460e+00 ...  \n",
       "1     [-0.8870298  -0.45862535 -3.3064713  -0.091987...  \n",
       "2     [ 9.11974728e-01  1.03492856e+00 -1.52655876e+...  \n",
       "3     [-0.90010715 -0.37471777 -3.003909   -0.017782...  \n",
       "4     [-8.3860934e-02 -2.7152100e-01 -3.4049506e+00 ...  \n",
       "...                                                 ...  \n",
       "5248  [-1.4767352   0.04409365 -2.265938    0.227724...  \n",
       "5249  [-2.03082055e-01  8.64372015e-01 -3.53538036e+...  \n",
       "5250  [-8.06897342e-01  1.52280945e-02 -2.08817863e+...  \n",
       "5251  [-6.59209251e-01  1.89325139e-01 -2.40648055e+...  \n",
       "5252  [-0.37164244  0.2070003  -2.5946207  -0.715533...  \n",
       "\n",
       "[5253 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(INTERMEDIATE_DIR, notebook_config.LOOV_INPUT_NAME))\n",
    "df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "328889c4-a93d-441a-bcd1-15696b1338ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_df=0.9, min_df=0.05, ngram_range=(3, 5),\n",
       "                strip_accents=&#x27;unicode&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.9, min_df=0.05, ngram_range=(3, 5),\n",
       "                strip_accents=&#x27;unicode&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_df=0.9, min_df=0.05, ngram_range=(3, 5),\n",
       "                strip_accents='unicode')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "#https://aclanthology.org/2020.aespen-1.6.pdf\n",
    "vectorizer = TfidfVectorizer(strip_accents=\"unicode\",\n",
    "                             ngram_range=(3,5), \n",
    "                             max_df=0.9, \n",
    "                             min_df=0.05)\n",
    "vectorizer.fit(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66754485-1140-4f76-bc04-aae029ad31fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=1133, n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=1133, n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=1133, n_jobs=-1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import skops.io as sio\n",
    "\n",
    "\n",
    "file = os.path.join(INTERMEDIATE_DIR, notebook_config.MODEL_FILE_NAME)\n",
    "best_model = sio.load(file, trusted=True)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ae9fe2-e09c-4e7b-8c12-887bb31fa79f",
   "metadata": {},
   "source": [
    "## Running LOOV\n",
    "\n",
    "This procedure when using an Ensemble classifier can anywhere from 13 to 27 hours uisng all processing power, depending on the number of parameters, estimator and hardware. Thus, we will only run the script for a subset of the dataset. We will also flush the results to disk for every iterations for data safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c251973-7fbf-4f96-8c59-777e0ab981aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "def validate(essay_id: str) -> tuple[float, pd.Series]:\n",
    "    \"\"\"o\n",
    "    Validate a trained model on a specific essay identified by its ID.\n",
    "\n",
    "    :param essay_id: A string specifying the ID of the essay to be validated.\n",
    "    :type essay_id: str\n",
    "\n",
    "    :return: A tuple containing the predicted probabilities and the text of the specified essay.\n",
    "             The predicted probabilities are generated by the trained model.\n",
    "    :rtype: tuple[float, pd.Series]\n",
    "\n",
    "    :raises ValueError: If the specified essay ID does not have a unique match in the dataset.\n",
    "    \"\"\"\n",
    "    essay_train = df[~df.id.eq(essay_id)]\n",
    "    essay_test = df[df.id.eq(essay_id)]\n",
    "    \n",
    "    if essay_test.shape[0] != 1:\n",
    "        raise ValueError(f\"Error id={essay_id} shape={essay_test.shape}\")\n",
    "        \n",
    "    model = clone(best_model)\n",
    "    model = model.fit(vectorizer.transform(essay_train.text), essay_train.generated)\n",
    "\n",
    "    return model.predict_proba(vectorizer.transform(essay_test.text)), essay_test.text\n",
    "\n",
    "\n",
    "def csv_output(df: pd.DataFrame, filename: str) -> None:\n",
    "    \"\"\"\n",
    "    Save a pandas DataFrame to a CSV file.\n",
    "\n",
    "    :param df: The DataFrame to be saved.\n",
    "    :type df: pd.DataFrame\n",
    "\n",
    "    :param filename: The name of the CSV file.\n",
    "    :type filename: str\n",
    "\n",
    "    :return: This function does not return anything.\n",
    "    :rtype: None\n",
    "    \"\"\"\n",
    "    file = os.path.join(OUTPUT_DIR, filename)\n",
    "    df.to_csv(file, encoding = 'utf8')\n",
    "    print(f\"File saved successfully as {file}\")\n",
    "\n",
    "\n",
    "def batch_validate(essay_id: str, file: str) -> None:\n",
    "    \"\"\"\n",
    "    Batch validate a trained model on a specific essay identified by its ID and append results to a CSV file.\n",
    "\n",
    "    :param essay_id: A string specifying the ID of the essay to be validated.\n",
    "    :type essay_id: str\n",
    "    :param file: A string specifying the name of the CSV file to which the results will be appended.\n",
    "    :type file: str\n",
    "\n",
    "    :return: None\n",
    "\n",
    "    :raises Exception: If an error occurs during the validation process, the exception is printed, \n",
    "    and the function returns.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # get rid of nested array\n",
    "        res, text = validate(essay_id)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return\n",
    "\n",
    "    res_df = pd.DataFrame({\"id\": [essay_id], \n",
    "                           \"text\": text.iloc[0],\n",
    "                           \"proba\": [res[0][1]]})\n",
    "    \n",
    "    # if no error append results to disk\n",
    "    # since the computational cost is absolutely enormous, a few IO operations per iteration\n",
    "    # don't hurt efficiency\n",
    "    old_df = pd.read_csv(file).loc[:, [\"id\", \"text\", \"proba\"]]\n",
    "    new_df = pd.concat([old_df, res_df])\n",
    "    new_df.to_csv(file, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18df64d8-5f82-4626-aef1-0aefbdf6d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "file = os.path.join(INTERMEDIATE_DIR, notebook_config.LOOV_RES_NAME)\n",
    "\n",
    "# create or overwrite empty file\n",
    "try:\n",
    "    previous_progress_df = pd.read_csv(file)\n",
    "    if len(previous_progress_df) == 0:\n",
    "        previous_ids = {}\n",
    "    else:\n",
    "        previous_ids = {str(id) for id in previous_progress_df.id}\n",
    "except FileNotFoundError:\n",
    "    # create empty csv file\n",
    "    previous_progress_df = pd.DataFrame({\"id\": [], \"text\": [] , \"proba\": []})\n",
    "    previous_progress_df.to_csv(file)\n",
    "    previous_ids = {}\n",
    "\n",
    "ids = df[df.generated == 1].id\n",
    "new_ids = [id for id in ids if str(id) not in previous_ids]\n",
    "random.shuffle(new_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9035dc6-a262-4807-a8f8-8abc90e68616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Leave One Out validation for generated texts...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6efbcd159ca14c829c6dd487241dca18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3878 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6816\\2028916179.py:47: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df = pd.concat([old_df, res_df])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error id=888804688479382258 shape=(2, 7)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning Leave One Out validation for generated texts...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tqdm(new_ids):\n\u001b[1;32m----> 3\u001b[0m     batch_validate(\u001b[38;5;28mid\u001b[39m, file\u001b[38;5;241m=\u001b[39mfile)\n",
      "Cell \u001b[1;32mIn[16], line 38\u001b[0m, in \u001b[0;36mbatch_validate\u001b[1;34m(essay_id, file)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_validate\u001b[39m(essay_id, file):\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;66;03m# get rid of nested array\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m         res, text \u001b[38;5;241m=\u001b[39m validate(essay_id)\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;28mprint\u001b[39m(e)\n",
      "Cell \u001b[1;32mIn[16], line 12\u001b[0m, in \u001b[0;36mvalidate\u001b[1;34m(essay_id)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError id=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00messay_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00messay_test\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m clone(best_model)\n\u001b[1;32m---> 12\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(vectorizer\u001b[38;5;241m.\u001b[39mtransform(essay_train\u001b[38;5;241m.\u001b[39mtext), essay_train\u001b[38;5;241m.\u001b[39mgenerated)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mpredict_proba(vectorizer\u001b[38;5;241m.\u001b[39mtransform(essay_test\u001b[38;5;241m.\u001b[39mtext)), essay_test\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\manis\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\manis\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    457\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    458\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    459\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    460\u001b[0m )(\n\u001b[0;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    462\u001b[0m         t,\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[0;32m    464\u001b[0m         X,\n\u001b[0;32m    465\u001b[0m         y,\n\u001b[0;32m    466\u001b[0m         sample_weight,\n\u001b[0;32m    467\u001b[0m         i,\n\u001b[0;32m    468\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[0;32m    469\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    470\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m    471\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[0;32m    472\u001b[0m     )\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[0;32m    474\u001b[0m )\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\manis\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\manis\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\manis\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\manis\\Lib\\multiprocessing\\pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 768\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[0;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\manis\\Lib\\multiprocessing\\pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 765\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event\u001b[38;5;241m.\u001b[39mwait(timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\manis\\Lib\\threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    620\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 622\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\manis\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Running Leave One Out validation for generated texts...\")\n",
    "for id in tqdm(new_ids):\n",
    "    batch_validate(id, file=file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
