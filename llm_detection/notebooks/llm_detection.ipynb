{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9438e4c-51bd-4571-8fa6-f149e8da7d53",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f8f782-1457-4600-b695-9d93592574c0",
   "metadata": {},
   "source": [
    "Check these out later: https://www.tutorialspoint.com/natural_language_toolkit/natural_language_toolkit_synonym_antonym_replacement.htm, https://www.kaggle.com/code/rohitsingh9990/data-augmentation-by-synonym-replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa2fed8d-eb1a-47fe-93bf-45181b8d4e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "DATA_PATH = os.path.join(\"..\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd9591a6-74da-423d-9e85-eb0252be86fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0059830c</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005db917</td>\n",
       "      <td>0</td>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008f63e3</td>\n",
       "      <td>0</td>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00940276</td>\n",
       "      <td>0</td>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00c39458</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>fe6ff9a5</td>\n",
       "      <td>1</td>\n",
       "      <td>There has been a fuss about the Elector Colleg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>ff669174</td>\n",
       "      <td>0</td>\n",
       "      <td>Limiting car usage has many advantages. Such a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>ffa247e0</td>\n",
       "      <td>0</td>\n",
       "      <td>There's a new trend that has been developing f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>ffc237e9</td>\n",
       "      <td>0</td>\n",
       "      <td>As we all know cars are a big part of our soci...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>ffe1ca0d</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars have been around since the 1800's and hav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1378 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  prompt_id                                               text  \\\n",
       "0     0059830c          0  Cars. Cars have been around since they became ...   \n",
       "1     005db917          0  Transportation is a large necessity in most co...   \n",
       "2     008f63e3          0  \"America's love affair with it's vehicles seem...   \n",
       "3     00940276          0  How often do you ride in a car? Do you drive a...   \n",
       "4     00c39458          0  Cars are a wonderful thing. They are perhaps o...   \n",
       "...        ...        ...                                                ...   \n",
       "1373  fe6ff9a5          1  There has been a fuss about the Elector Colleg...   \n",
       "1374  ff669174          0  Limiting car usage has many advantages. Such a...   \n",
       "1375  ffa247e0          0  There's a new trend that has been developing f...   \n",
       "1376  ffc237e9          0  As we all know cars are a big part of our soci...   \n",
       "1377  ffe1ca0d          0  Cars have been around since the 1800's and hav...   \n",
       "\n",
       "      generated  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "1373          0  \n",
       "1374          0  \n",
       "1375          0  \n",
       "1376          0  \n",
       "1377          0  \n",
       "\n",
       "[1378 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATA_PATH, \"train_essays.csv\"))\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a2d9454-fb82-4ffa-94e7-038190caca1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>82131f68</td>\n",
       "      <td>1</td>\n",
       "      <td>This essay will analyze, discuss and prove one...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>86fe4f18</td>\n",
       "      <td>1</td>\n",
       "      <td>I strongly believe that the Electoral College ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>eafb8a56</td>\n",
       "      <td>0</td>\n",
       "      <td>Limiting car use causes pollution, increases c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  prompt_id                                               text  \\\n",
       "704   82131f68          1  This essay will analyze, discuss and prove one...   \n",
       "740   86fe4f18          1  I strongly believe that the Electoral College ...   \n",
       "1262  eafb8a56          0  Limiting car use causes pollution, increases c...   \n",
       "\n",
       "      generated  \n",
       "704           1  \n",
       "740           1  \n",
       "1262          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.generated == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4af26a4e-793d-45f9-bab1-a5eac1ce2bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In recent years, there has been a growing glob...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The advantages of limiting car usage are evide...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The global movement towards limiting car usage...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The advantages of limiting car usage are becom...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The advantages of limiting car usage are manif...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>There has been a fuss about the Elector Colleg...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>Limiting car usage has many advantages. Such a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>There's a new trend that has been developing f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>As we all know cars are a big part of our soci...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>Cars have been around since the 1800's and hav...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1490 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text prompt_id generated\n",
       "0     In recent years, there has been a growing glob...         0         1\n",
       "1     The advantages of limiting car usage are evide...         0         1\n",
       "2     The global movement towards limiting car usage...         0         1\n",
       "3     The advantages of limiting car usage are becom...         0         1\n",
       "4     The advantages of limiting car usage are manif...         0         1\n",
       "...                                                 ...       ...       ...\n",
       "1373  There has been a fuss about the Elector Colleg...         1         0\n",
       "1374  Limiting car usage has many advantages. Such a...         0         0\n",
       "1375  There's a new trend that has been developing f...         0         0\n",
       "1376  As we all know cars are a big part of our soci...         0         0\n",
       "1377  Cars have been around since the 1800's and hav...         0         0\n",
       "\n",
       "[1490 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_gpt(file: str) -> pd.Series:\n",
    "    with open(os.path.join(DATA_PATH, file), encoding=\"utf8\") as f:\n",
    "        contents = f.read()\n",
    "    responses = list(filter(lambda x: x.startswith(\" ChatGPT\"), \n",
    "                        contents.split(\"##\")))\n",
    "    clear_responses = [res.replace(\"ChatGPT\", \"\").replace(\"~\", \"\").strip() \n",
    "                            for res in responses]\n",
    "    return pd.Series(clear_responses)\n",
    "\n",
    "\n",
    "chat_gpt_environment = read_gpt(\"chatgpt_cars.md\")\n",
    "envir_df = pd.DataFrame({\"text\": chat_gpt_environment, \n",
    "                         \"prompt_id\": np.zeros_like(chat_gpt_environment),\n",
    "                         \"generated\": np.ones_like(chat_gpt_environment)})\n",
    "\n",
    "chat_gpt_electoral = read_gpt(\"chatgpt_electoral.md\")\n",
    "elect_df = pd.DataFrame({\"text\": chat_gpt_electoral, \n",
    "                         \"prompt_id\": np.ones_like(chat_gpt_electoral),\n",
    "                         \"generated\": np.ones_like(chat_gpt_electoral)})\n",
    "\n",
    "df = pd.concat([envir_df, \n",
    "                elect_df, \n",
    "                train_df.loc[:, [\"text\", \"prompt_id\", \"generated\"]]])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "257e9a2a-0e07-4dd9-82b9-4484c7f4bbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.loc[df.text.apply(lambda x: x.startswith(\"Dear\"))].iloc[3][-15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "606591a4-d5b7-452f-8b04-64315e0f3854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dear Senator,\\n\\nI am writing to express my support for retaining the Electoral College as the method for electing the President of the United States. While critics argue for its abolition, citing concerns about fairness and potential issues, it is crucial to consider the nuanced advantages highlighted by various sources, including the Office of the Federal Register and Judge Richard A. Posner.\\n\\nThe Electoral College, as explained by the Federal Register, was established as a compromise between direct congressional election and a popular vote, ensuring a balanced representation of federal and state interests (Federal Register, 1). This compromise remains relevant today, preventing the domination of densely populated areas and fostering a more inclusive system.\\n\\nCritics, such as Bradford Plumer, point out flaws in the Electoral College, emphasizing the potential for elector confusion and the so-called \"disaster factor\" (Plumer, 10-11). However, Judge Posner provides a more balanced perspective, outlining practical reasons for retaining the Electoral College, including the certainty of outcome and the avoidance of runoff elections (Posner, 18, 22).\\n\\nThe certainty of outcome, as argued by Posner, is a crucial advantage of the Electoral College. The winner-take-all system ensures that the winning candidate\\'s share of the electoral vote typically exceeds their share of the popular vote, reducing the likelihood of disputed election results (Posner, 18). This certainty is essential for maintaining the stability and integrity of the electoral process.\\n\\nPosner also highlights the Electoral College\\'s role in fostering trans-regional appeal for presidential candidates, preventing candidates with only regional support from dominating the political landscape (Posner, 19). This ensures that the President represents a broader range of interests, preventing the marginalization of certain regions.\\n\\nThe focus on swing states, another point emphasized by Posner, is a critical aspect of the Electoral College. The winner-take-all method encourages candidates to concentrate their efforts on states where the outcome is uncertain, fostering a more informed and engaged electorate (Posner, 20). This ensures that voters in toss-up states are more likely to pay close attention to the campaign and make thoughtful, informed decisions.\\n\\nIn conclusion, while the critics present valid concerns, it is essential to acknowledge the nuanced advantages of the Electoral College. The system maintains stability, prevents the domination of densely populated areas, and encourages candidates to consider the diverse interests of citizens across the nation. Rather than abolishing the Electoral College, efforts should be directed towards refining and strengthening the system to address its perceived shortcomings.\\n\\nSincerely,\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "bracket_regex = r\"\\[.*?\\]\"\n",
    "\n",
    "df.text = df.text.apply(lambda x: re.sub(bracket_regex, \"\", x))\n",
    "df.text.loc[df.text.apply(lambda x: x.startswith(\"Dear\"))].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "185039ed-6963-4334-8339-faf2845844af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dear Senator , I writing express support retaining Electoral College method electing President United States . While critics argue abolition , citing concerns fairness potential issues , crucial consider nuanced advantages highlighted various sources , including Office Federal Register Judge Richard A. Posner . The Electoral College , explained Federal Register , established compromise direct congressional election popular vote , ensuring balanced representation federal state interests ( Federal Register , 1 ) . This compromise remains relevant today , preventing domination densely populated areas fostering inclusive system . Critics , Bradford Plumer , point flaws Electoral College , emphasizing potential elector confusion so-called `` disaster factor '' ( Plumer , 10-11 ) . However , Judge Posner provides balanced perspective , outlining practical reasons retaining Electoral College , including certainty outcome avoidance runoff elections ( Posner , 18 , 22 ) . The certainty outcome , argued Posner , crucial advantage Electoral College . The winner-take-all system ensures winning candidate 's share electoral vote typically exceeds share popular vote , reducing likelihood disputed election results ( Posner , 18 ) . This certainty essential maintaining stability integrity electoral process . Posner also highlights Electoral College 's role fostering trans-regional appeal presidential candidates , preventing candidates regional support dominating political landscape ( Posner , 19 ) . This ensures President represents broader range interests , preventing marginalization certain regions . The focus swing states , another point emphasized Posner , critical aspect Electoral College . The winner-take-all method encourages candidates concentrate efforts states outcome uncertain , fostering informed engaged electorate ( Posner , 20 ) . This ensures voters toss-up states likely pay close attention campaign make thoughtful , informed decisions . In conclusion , critics present valid concerns , essential acknowledge nuanced advantages Electoral College . The system maintains stability , prevents domination densely populated areas , encourages candidates consider diverse interests citizens across nation . Rather abolishing Electoral College , efforts directed towards refining strengthening system address perceived shortcomings . Sincerely ,\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections.abc import Iterable\n",
    "\n",
    "\n",
    "# https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "def remove_stopwords(words: str, stopwords: Iterable[str]) -> str:\n",
    "    word_tokens = word_tokenize(words)\n",
    "    # converts the words in word_tokens to lower case and then checks whether \n",
    "    #they are present in stop_words or not\n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "    #with no lower case conversion\n",
    "    filtered_sentence = []\n",
    "     \n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    return \" \".join(filtered_sentence)\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df.text = df.text.apply(lambda x: remove_stopwords(x, stop_words))\n",
    "df.text.loc[df.text.apply(lambda x: x.startswith(\"Dear\"))].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d126d4c0-2dba-49fd-b367-8984362f9a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.generated == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f3514aa-5559-4436-9993-185b1116bbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32b83646-6555-4866-8221-3cce2dfcb710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         object\n",
       "prompt_id    object\n",
       "generated    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec602713-df68-4529-b320-200d8ae46345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         object\n",
       "prompt_id     int32\n",
       "generated     int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.prompt_id = df.prompt_id.astype(int)\n",
    "df.generated = df.generated.astype(int)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124c4a3e-9ced-4036-a0b9-b2ad60fb2f74",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6bb3cc5-0b09-4724-b155-9a2d321aacc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data_train, data_test = train_test_split(df,\n",
    "                                         train_size=0.75, \n",
    "                                         test_size=0.25, \n",
    "                                         stratify=df.generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a6579fc-63d7-403c-951f-bd3af78760e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer().fit(data_train.text)\n",
    "x_train = vectorizer.transform(data_train.text)\n",
    "y_train = data_train.generated.values\n",
    "x_test = vectorizer.transform(data_test.text)\n",
    "y_test = data_test.generated.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470494ba-7eb3-496d-9d83-d8b83a94d59b",
   "metadata": {},
   "source": [
    "The metric we will be using is Macro-F1 average.\n",
    "\n",
    "- **F1** is a metric used to balance the need for making sure our classifications for a category are both correct (precision) and represent as many of the actual cases of the category as possible (recall).\n",
    "- **Macro-F1** is the unweighted average of all F1 metrics for each class. We choose Macro F1 instead of a weighted average because we have an unbalanced dataset (Generated essays data are a small fraction of overall essays)\n",
    "\n",
    "\n",
    "Thus, we want to use a metric which favors both thorough and precise classifiers, and which also assigns equal importance to our smaller classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e502c8d8-64f1-42d5-8885-74e4d7dccae1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def cross_val_res(model, x, y, scoring=None, cv=10):\n",
    "    \"\"\"\n",
    "    Minor utility method, wraping cross_val_score.\n",
    "    \"\"\"\n",
    "    if scoring is None:\n",
    "        scoring = \"f1_macro\"\n",
    "    res = cross_val_score(model, x, y, cv=cv, scoring=scoring)\n",
    "    return res.mean(), res.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8916b8b8-a7f5-4913-ab72-08bccaeee0f8",
   "metadata": {},
   "source": [
    "### Dummy Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28556888-ed28-4fa2-ab31-4408f5edabcd",
   "metadata": {},
   "source": [
    "We will first run a \"fake\" classifier which only guesses the majority category.\n",
    "\n",
    "This dummy model thus completely disregards the input features and serves as a useful baseline with which to compare the subsequent classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18f8d6ca-c3af-4e0d-a808-60b5515bcb12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier mean macro F1-score 0.4800, std: 0.0011\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "majority_model = DummyClassifier(strategy=\"most_frequent\")\n",
    "res = cross_val_res(majority_model, x_train, y_train)\n",
    "print(f\"Dummy Classifier mean macro F1-score {res[0]:.4f}, std: {res[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7735259-ac2f-44ef-abb2-edfb09d296de",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f69629-6178-4b26-9703-630c507babe7",
   "metadata": {},
   "source": [
    "Naive Bayes is a very cheap and easy-to-interpret classifier, which checks for the probability that each individual word in the text will belong in any language. We generally want to use the simplest model for the job, and so we start with this reliable model which has proven itself in many fields in the past.\n",
    "\n",
    "The `sklearn` library gives us access to many variations of Naive Bayes, each specialized in its own field. For this NLP task, we will be using `MultinomialNB`, which was suggested by [this blogpost](https://towardsdatascience.com/naive-bayes-classifiers-for-text-classification-be0d133d35ba)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3403adf6-3e64-4431-ac50-8f68df3a14c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes mean macro F1-score 0.5508, std: 0.0776\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# naive bayes needs dense arrays to work \n",
    "naive_x_train = x_train.toarray()\n",
    "naive_x_test = x_test.toarray()\n",
    "\n",
    "naive_model = MultinomialNB()\n",
    "res = cross_val_res(naive_model, naive_x_train, y_train)\n",
    "print(f\"Naive Bayes mean macro F1-score {res[0]:.4f}, std: {res[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24694265-7406-4b8a-a2d1-cb8a98cf5f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       344\n",
      "           1       1.00      0.34      0.51        29\n",
      "\n",
      "    accuracy                           0.95       373\n",
      "   macro avg       0.97      0.67      0.74       373\n",
      "weighted avg       0.95      0.95      0.94       373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_model = MultinomialNB().fit(x_train, y_train)\n",
    "naive_res = naive_model.predict(x_test)\n",
    "print(classification_report(y_test, naive_res, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d7e4a0-2623-46e1-9cbc-6ae28bb87568",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c15dbe-a7c6-40e5-a18e-ef52822c1b01",
   "metadata": {},
   "source": [
    "LogisticRegression despite its name is a linear classifier, meaning that it attempts to linearly separate the data into distinct categories. This interpretation does not apply well to a NLP task, but means that the classifier retains some very useful properties:\n",
    "\n",
    "- The solution we get is a global optimum, meaning that it's the best we can get with the provided data. This means no hyper-parameter tuning is necessary and we can use the classifier as-is.\n",
    "- It's a simple and very easy to compute classifier, since it solves a (mathematically simple) linear problem, albeit with some restrictions (technically those restrictions force it to use gradient descent, but the calculations are much easier than say, a neural network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50250bf6-0adc-4bfe-b334-6374c29ebbb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression mean macro F1-score 0.9820, std: 0.0248\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    # ignore warnings about deprecated methods in libraries\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    lr = LogisticRegression(max_iter=1000)\n",
    "    res = cross_val_res(lr, x_train, y_train)\n",
    "    print(f\"Logistic Regression mean macro F1-score {res[0]:.4f}, std: {res[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c625833a-4843-4a2f-a73b-0c9fcb1bff9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       344\n",
      "           1       1.00      1.00      1.00        29\n",
      "\n",
      "    accuracy                           1.00       373\n",
      "   macro avg       1.00      1.00      1.00       373\n",
      "weighted avg       1.00      1.00      1.00       373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    lr = LogisticRegression(max_iter=1000).fit(x_train, y_train)\n",
    "    lr_res = lr.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, lr_res, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70ccc10-19c4-482e-b506-47b85a187d63",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8c9d54-b472-4b37-8068-1d4579acadee",
   "metadata": {},
   "source": [
    "Random Forest is an ensemble algorithm, which means it uses many simpler algorithms which then \"vote\" on a final decision. It has proven to be a good classifier on complex tasks, it combats overfitting by design (essentially by utilizing random chance in its training phase) and is still fairly easy to interpret.\n",
    "\n",
    "The drawback is first and foremost computational, since we need to train many smaller classifiers, which may by themselves be computationally expensive (this is somewhat offset by the fact that the classifiers are indepednent and can be computed in parallel). Additionally, Random Forest is a non-parametric method which means that it is generally memory-intensive and may be slow to run on operational data. Finally, we also need to tune hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "242df209-18a9-4652-9863-31a8560a1d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest mean macro F1: 0.9869, std: 0.0125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "forest_model = RandomForestClassifier(n_estimators=500,\n",
    "                                      criterion=\"entropy\")\n",
    "res = cross_val_res(forest_model, x_train, y_train, cv=5)\n",
    "print(f\"Random Forest mean macro F1: {res[0]:.4f}, std: {res[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d99837f-f70e-4484-b248-347a7909878e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       344\n",
      "           1       1.00      1.00      1.00        29\n",
      "\n",
      "    accuracy                           1.00       373\n",
      "   macro avg       1.00      1.00      1.00       373\n",
      "weighted avg       1.00      1.00      1.00       373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest_model = RandomForestClassifier(n_estimators=500, \n",
    "                                      criterion=\"entropy\").fit(x_train, y_train)\n",
    "forest_pred = forest_model.predict(x_test)\n",
    "print(classification_report(y_test, forest_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f4ffe4-87f9-4179-9f43-c2641b26f015",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca27a788-11b2-4509-8218-8e906f694a67",
   "metadata": {},
   "source": [
    "Adaboost is the logical conclusion of Random Forests, where each voter considers a very specific \"rule\" that needs to be followed. The next voter then considers the most important rule to distinguish between the categories for all the clases that the first could not reliably classify, and so on.\n",
    "\n",
    "This classifier is generally more compact and competent than a simple Random Forest, but is more computationally expensive during training because we cannot train it in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2acb17ba-62b2-4ae1-a27c-c0793176747a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost mean macro F1: 0.9871, std: 0.0046\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "ada_model = AdaBoostClassifier(n_estimators=150)\n",
    "res = cross_val_res(ada_model, x_train, y_train, cv=3)\n",
    "print(f\"AdaBoost mean macro F1: {res[0]:.4f}, std: {res[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca9920f5-1d64-4fe4-ad7c-f7c2eaafa9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       344\n",
      "           1       1.00      1.00      1.00        29\n",
      "\n",
      "    accuracy                           1.00       373\n",
      "   macro avg       1.00      1.00      1.00       373\n",
      "weighted avg       1.00      1.00      1.00       373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "ada_model = AdaBoostClassifier(n_estimators=150).fit(x_train, y_train)\n",
    "ada_pred = ada_model.predict(x_test)\n",
    "print(classification_report(y_test, ada_pred, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
